<!DOCTYPE html>

<html lang="en-US" xml:lang="en-US">
<head><title>Message passing GANs</title>
<meta charset="utf-8"/>
<meta content="TeX4ht (https://tug.org/tex4ht/)" name="generator"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<link href="main.css" rel="stylesheet" type="text/css"/>
<meta content="main.tex" name="src"/>
<script async="async" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/mml-chtml.js" type="text/javascript"></script>
<link href="style.css" rel="stylesheet" type="text/css"/>
<link href="assets/icon.png" rel="icon" type="image/x-icon"/>
</head><body>
<nav class="TOC"><span class="mainToc"><a href="index.html"><img alt="Symmetries, QFT, &amp; The Standard Model" class="mainTocLogo" src="assets/logo.png" width="100%"/></a></span>
<span class="likepartToc"><a href="Frontmatter.html#front-matter">Front matter</a></span>
<span class="likepartToc"><a href="AbstractoftheDissertation.html#abstract-of-the-dissertation">Abstract of the Dissertation</a></span>
<span class="likepartToc"><a href="Introduction.html#introduction">Introduction</a></span>
<span class="partToc">I  <a href="TheoreticalBackground.html#theoretical-background">Theoretical Background</a></span>
<span class="partToc">II  <a href="ExperimentalBackground.html#experimental-background">Experimental Background</a></span>
<span class="partToc">III  <a href="AIMLandStatisticsBackground.html#aiml-and-statistics-background">AI/ML and Statistics Background</a></span>
<span class="partToc">IV  <a href="AcceleratingSimulationswithAI.html#accelerating-simulations-with-ai">Accelerating Simulations with AI</a></span>
<span class="chapterToc">9 <a href="IntroductionandtheJetNetDataset.html#introduction-and-the-jetnet-dataset">Introduction and the JetNet Dataset</a></span>
<span class="chapterToc">10 <a href="Generativemodelsforfastparticlecloudsimulations.html#generative-models-for-fast-particlecloud-simulations">Generative models for fast particle-cloud simulations</a></span>
<span class="sectionToc">10.1 <a href="#message-passing-gans">Message passing GANs</a></span>
<span class="subsectionToc">10.1.1 <a href="#evaluation">Evaluation</a></span>
<span class="subsectionToc">10.1.2 <a href="#architecture">Architecture</a></span>
<span class="subsectionToc">10.1.3 <a href="#experiments-on-mnist-handwritten-digits">Experiments on MNIST handwritten digits</a></span>
<span class="subsectionToc">10.1.4 <a href="#experiments-on-jets">Experiments on jets</a></span>
<span class="subsectionToc">10.1.5 <a href="#summary2">Summary</a></span>
<span class="sectionToc">10.2 <a href="Generativeadversarialparticletransformers.html#generative-adversarial-particle-transformers">Generative adversarial particle transformers</a></span>
<span class="chapterToc">11 <a href="Validatingandcomparingfastsimulations.html#validating-and-comparing-fast-simulations">Validating and comparing fast simulations</a></span>
<span class="chapterToc">12 <a href="Conclusionandimpact.html#conclusion-and-impact">Conclusion and impact</a></span>
<span class="partToc">V  <a href="SearchesforHighEnergyHiggsBosonPairs.html#searches-for-high-energy-higgs-boson-pairs">Searches for High Energy Higgs Boson Pairs</a></span>
<span class="partToc">VI  <a href="AIforJets.html#ai-for-jets">AI for Jets</a></span>
<span class="partToc">VII  <a href="Appendix.html#appendix">Appendix</a></span>
<span class="likepartToc"><a href="Bibliography.html#bibliography">Bibliography</a></span>
</nav>
<main class="main-content"><a class="header-link" href="https://github.com/rkansal47/dissertation" rel="noopener noreferrer" style="top: 10px; right: 12px;" target="_blank"><img alt="GitHub Repository" class="header-icon" src="https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png" style="width: 32px; height: 32px;"/></a><a class="header-link" href="https://github.com/rkansal47/dissertation/blob/gh-pages/dissertation.pdf?raw=true" rel="noopener noreferrer" style="top: 12px; right: 54px;" target="_blank"><img alt="Download PDF" class="header-icon" src="assets/download.png" style="width: 25px; height: 25px;"/></a>
<nav class="crosslinks-top"> <a href="Generativemodelsforfastparticlecloudsimulations.html">⭠</a> <a href="Generativeadversarialparticletransformers.html">⭢</a> </nav>
<h3 class="sectionHead" id="message-passing-gans"><span class="titlemark">10.1   </span> <a id="x51-21000010.1"></a>Message passing GANs</h3>
<!--  l. 7  --><p class="noindent">In this chapter we describe two novel generative models for fast simulations of particle
clouds in HEP. We first introduce the message-passing generative adversarial network
(MPGAN) trained on high-energy <span class="small-caps">JetNet</span> jets. To our knowledge, it was the first
generative model in HEP to effectively simulate point cloud data, and represented a
                                                                                

                                                                                
breakthrough in the performance of ML-based fast simulations, leveraging sparse and
efficient representations naturally suited to our data. It builds on top of the success of
graph neural networks (GNNs) in learning from point clouds in computer vision, but is
designed to take advantage of additional key inductive biases in HEP data,
such as the non-local correlations between particles in a jet and their varying
cardinalities.
</p><!--  l. 12  --><p class="indent">       The landscape of point cloud generative models in HEP and computer
vision at the time of MPGAN’s publication was detailed in Chapter <a href="Autoencodersandgenerativemodels.html#previous-work">7.3.3<!--  tex4ht:ref: sec:04_mpgan_genhep   --></a>.
In this section, we first discuss evaluation metrics used to compare MPGAN
to existing models (Section <a href="#evaluation">10.1.1<!--  tex4ht:ref: sec:04_mpgan_geneval   --></a>) before describing the model architecture
(Section <a href="#architecture">10.1.2<!--  tex4ht:ref: sec:04_mpgan_arch   --></a>). We then discuss experimental results, first on MNIST handwritten
digits as a testbench in Section <a href="#experiments-on-mnist-handwritten-digits">10.1.3<!--  tex4ht:ref: sec:04_mpgan_mnist   --></a>, and finally on the <span class="small-caps">JetNet</span> dataset in
Section <a href="#experiments-on-jets">10.1.4<!--  tex4ht:ref: sec:04_mpgan_exp   --></a>.
</p><!--  l. 17  --><p class="noindent">
</p>
<h4 class="subsectionHead" id="evaluation"><span class="titlemark">10.1.1   </span> <a id="x51-21100010.1.1"></a>Evaluation</h4>
<!--  l. 20  --><p class="noindent">Evaluating generative models is a difficult task; however, there has been extensive work
in this area in both the physics and computer-vision communities. We provide here a
brief overview of the metrics used for comparing MPGAN and the baseline models
                                                                                

                                                                                
discussed above, leaving a more detailed discussion, as well as an introduction to the
novel metrics we develop for this task, to Chapter <a href="Validatingandcomparingfastsimulations.html#validating-and-comparing-fast-simulations">11<!--  tex4ht:ref: sec:04_evaluating   --></a>.
</p><!--  l. 23  --><p class="noindent">
</p>
<h5 class="subsubsectionHead" id="physicsinspired-metrics"><a id="x51-212000"></a>Physics-inspired metrics</h5>
<!--  l. 25  --><p class="noindent">An accurate jet simulation algorithm should reproduce both low-level and high-level
features (such as those described in Chapter <a href="Autoencodersandgenerativemodels.html#previous-work">7.3.3<!--  tex4ht:ref: sec:04_mpgan_genhep   --></a>); hence, a standard method of
validating generative models, which we too employ, is to compare the distributions of
such features between the real and generated samples [<a href="Bibliography.html#XPaganini_2017dwg">274</a>, <a href="Bibliography.html#XATL-SOFT-PUB-2020-006">275</a>, <a href="Bibliography.html#XSekmen_2016iql">310</a><span class="ec-lmbx-12">? ? ?</span>
].
</p><!--  l. 27  --><p class="indent">       For application in HEP, a generative model needs to produce jets with
physical features indistinguishable from real. Therefore, we propose the validation
criteria that differences between real and generated sample features may not
exceed those between sets of randomly chosen real samples. To verify this, we
use bootstrapping to compare between random samples of only real jets as a
baseline.
</p><!--  l. 31  --><p class="indent">       A practically useful set of features to validate against are the so-called
“energy-flow polynomials” (EFPs) [<a href="Bibliography.html#XKomiske_2017aww">311</a>], which are a type of multi-particle
                                                                                

                                                                                
correlation functions. Importantly, the set of all EFPs forms a linear basis for all
experimentally useful — i.e., all infrared- and colinear- (IRC-) safe — jet-level features
/ observables. Therefore, we claim that if we observe all EFP distributions
to be reproduced with high fidelity and to match the above criteria, we can
conclude with strong confidence that our model is outputting accurate particle
clouds.
</p><!--  l. 35  --><p class="noindent">
</p>
<h5 class="subsubsectionHead" id="computervisioninspired-metrics"><a id="x51-213000"></a>Computer-vision-inspired metrics</h5>
<!--  l. 36  --><p class="noindent">A popular metric for evaluating images which has been shown to be sensitive to output
quality and mode-collapse — though it has its limitations [<a href="Bibliography.html#Xborji2021">312</a>] — is the Fréchet
Inception Distance [<a href="Bibliography.html#XTTUR">313</a>] (FID). FID is defined as the Fréchet distance between
Gaussian distributions fitted to the activations of a fully-connected layer of
the Inception-v3 image classifier in response to real and generated samples.
We develop a particle-cloud-analogue of this metric, which we call Fréchet
ParticleNet Distance (FPND), using the state-of-the-art (SOTA) ParticleNet
graph convolutional jet classifier [<a href="Bibliography.html#XQu_2019gqs">225</a>] in lieu of the Inception network. We note
that FPND and comparing distributions as above are conceptually equivalent,
except here instead of physically meaningful and easily interpretable features,
                                                                                

                                                                                
we are comparing those found to be statistically optimum for distinguishing
jets.
</p><!--  l. 41  --><p class="indent">       Two common metrics for evaluating point cloud generators are coverage (COV) and
minimum matching distance (MMD) [<a href="Bibliography.html#Xrgan">288</a>]. Both involve finding the closest point cloud in a sample
<!--  l. 42  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mi>X</mi></math> to each cloud in
another sample <!--  l. 42  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Y</mi> </mrow></math>,
based on a metric such as the Chamfer distance or the earth
mover’s distance. Coverage is defined as the fraction of samples in
<!--  l. 43  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mi>X</mi></math> which were matched to
one in <!--  l. 43  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Y</mi> </mrow></math>, measuring thus the
diversity of the samples in <!--  l. 43  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Y</mi> </mrow></math>
relative to <!--  l. 43  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mi>X</mi></math>,
and MMD is the average distance between matched samples, measuring the quality of
samples. We use both, and due to drawbacks of the Chamfer distance pointed out in
Ref. [<a href="Bibliography.html#Xrgan">288</a>], for our distance metric choose only the analogue of the earth mover’s
distance for particle clouds a.k.a. the energy mover’s distance (EMD) [<a href="Bibliography.html#XKomiske_2019fks">314</a>]. We discuss
the effectiveness and complementarity of all four metrics in evaluating clouds in
Section <a href="#x51-222000doc">10.1.4.<!--  tex4ht:ref: sec:04_mpgan_results   --></a>.
</p><!--  l. 48  --><p class="noindent">
</p>
<h4 class="subsectionHead" id="architecture"><span class="titlemark">10.1.2   </span> <a id="x51-21400010.1.2"></a>Architecture</h4>
<!--  l. 51  --><p class="noindent">We describe now the architecture of the MPGAN model (Figure <a href="#top-the-mp-generator-uses-message-passing-to-generate-a-particle-cloud">10.1<!--  tex4ht:ref: fig:04_mpgan_arch   --></a>), noting
particle-cloud-motivated aspects compared to its r-GAN and GraphCNN-GAN
predecessors (see Chapter <a href="Autoencodersandgenerativemodels.html#previous-work">7.3.3<!--  tex4ht:ref: sec:04_mpgan_genhep   --></a>).
</p>
<figure class="figure" id="x51-214001r1"><span id="top-the-mp-generator-uses-message-passing-to-generate-a-particle-cloud"></span>
<div class="centerline"> <img alt="PIC" src="figures/04-ML4Sim/mpgan/mparch_wide-.png" style="max-width:100%"/> </div>
<figcaption class="caption"><span class="id"><span class="ec-lmbx-12">Figure 10.1. </span></span><span class="content">Top: The MP generator uses message passing to generate a particle
cloud. In blue is the initial latent vector and FC layer part of the MP-LFC variant.
Bottom: The MP discriminator uses message passing to classify an input particle
cloud as real or generated.                                                      </span></figcaption><!--  tex4ht:label?: x51-214001r1   -->
</figure>
<h5 class="subsubsectionHead" id="message-passing"><a id="x51-215000"></a>Message passing</h5>
<!--  l. 64  --><p class="noindent">Jets originate from the decay and hadronization of a single source-particle; hence, they
end up with important high-level jet features and a rich global structure, known as the
jet substructure [<span class="ec-lmbx-12">? </span>], stemming from the input particle. Indeed, any high-level
feature useful for analyzing jets, such as jet mass or multi-particle correlations, is
necessarily global [<a href="Bibliography.html#XKomiske_2017aww">311</a>]. Because of this, while past work in learning on point
clouds [<a href="Bibliography.html#XQu_2019gqs">225</a>, <a href="Bibliography.html#Xdynamicgraphcnn">315</a>, <a href="Bibliography.html#Xmonti2017geometric">316</a>], including GraphCNN-GAN, has used a locally connected graph
structure and convolutions for message passing, we choose a fully connected graph,
equally weighting messages from all particles in the clouds. Rather than subtracting
particle features for messages between particles, useful in graph convolutions to capture
local differences within a neighborhood, the respective features are concatenated
to preserve the global structure (the difference between particle features is
also only physically meaningful if they are in the 4-vector representation of
the Lorentz group). During the update step in the message passing we find it
empirically beneficial to incorporate a residual connection to previous particle
features.
</p><!--  l. 70  --><p class="indent">       The operation can be described as follows. For an
<!--  l. 71  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mi>N</mi></math>-particle
                                                                                

                                                                                
cloud <!--  l. 71  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mrow><mi>J</mi></mrow><mrow><mi>t</mi></mrow></msup> <mo class="MathClass-rel" stretchy="false">=</mo> <mo class="MathClass-open" stretchy="false">{</mo><msubsup><mrow><mi>p</mi></mrow><mrow>
<mn>1</mn></mrow><mrow><mi>t</mi></mrow></msubsup><mo class="MathClass-punc" stretchy="false">,</mo><mo class="MathClass-rel" stretchy="false">⋯</mo><mspace class="thinspace" width="0.17em"></mspace><mo class="MathClass-punc" stretchy="false">,</mo><msubsup><mrow><mi>p</mi></mrow><mrow>
<mi>N</mi></mrow><mrow><mi>t</mi></mrow></msubsup><mo class="MathClass-close" stretchy="false">}</mo></mrow></math> after
<!--  l. 71  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi></math> iterations of message
passing, with <!--  l. 71  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>t</mi> <mo class="MathClass-rel" stretchy="false">=</mo> <mn>0</mn></mrow></math>
corresponding to the original input cloud, each particle
<!--  l. 71  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow><mi>p</mi></mrow><mrow><mi>i</mi></mrow><mrow><mi>t</mi></mrow></msubsup></math> is represented
by features <!--  l. 71  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow><mstyle mathvariant="bold"><mi>h</mi></mstyle></mrow><mrow><mi>i</mi></mrow><mrow><mi>t</mi></mrow></msubsup></math>.
One iteration of message passing is then defined as
</p><!--  tex4ht:inline  --><!--  l. 76  --><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mtable class="align" columnalign="left" displaystyle="true">
<mtr><mtd class="align-odd" columnalign="right"><msubsup><mrow><mstyle mathvariant="bold"><mi>m</mi></mstyle></mrow><mrow><mi mathvariant="italic">ij</mi></mrow><mrow><mi>t</mi><mo class="MathClass-bin" stretchy="false">+</mo><mn>1</mn></mrow></msubsup></mtd>
<mtd class="align-even"> <mo class="MathClass-rel" stretchy="false">=</mo> <msubsup><mrow><mi>f</mi></mrow><mrow><mi>e</mi></mrow><mrow><mi>t</mi><mo class="MathClass-bin" stretchy="false">+</mo><mn>1</mn></mrow></msubsup><mo class="MathClass-open" stretchy="false">(</mo><msubsup><mrow><mstyle mathvariant="bold"><mi>h</mi></mstyle></mrow><mrow>
<mi>i</mi></mrow><mrow><mi>t</mi></mrow></msubsup> <mo class="MathClass-bin" stretchy="false">⊕</mo><msubsup><mrow><mstyle mathvariant="bold"><mi>h</mi></mstyle></mrow><mrow>
<mi>j</mi></mrow><mrow><mi>t</mi></mrow></msubsup><mo class="MathClass-close" stretchy="false">)</mo><mo class="MathClass-punc" stretchy="false">,</mo><mspace width="2em"></mspace></mtd>
<mtd class="align-label" columnalign="right"><mstyle class="label" id="x51-215001r1"></mstyle><!--  endlabel  --><mstyle class="maketag"><mtext>(10.1.1)</mtext></mstyle><mspace class="nbsp" width="0.33em"></mspace>
</mtd></mtr><mtr><mtd class="align-odd" columnalign="right"><msubsup><mrow><mstyle mathvariant="bold"><mi>h</mi></mstyle></mrow><mrow><mi>i</mi></mrow><mrow><mi>t</mi><mo class="MathClass-bin" stretchy="false">+</mo><mn>1</mn></mrow></msubsup></mtd>
<mtd class="align-even"> <mo class="MathClass-rel" stretchy="false">=</mo> <msubsup><mrow><mi>f</mi></mrow><mrow><mi>n</mi></mrow><mrow><mi>t</mi><mo class="MathClass-bin" stretchy="false">+</mo><mn>1</mn></mrow></msubsup><mo class="MathClass-open" stretchy="false">(</mo><msubsup><mrow><mstyle mathvariant="bold"><mi>h</mi></mstyle></mrow><mrow>
<mi>i</mi></mrow><mrow><mi>t</mi></mrow></msubsup> <mo class="MathClass-bin" stretchy="false">⊕</mo><munder class="msub"><mrow><mo>∑</mo>
</mrow><mrow><mi>j</mi><mo class="MathClass-rel" stretchy="false">∈</mo><mi>J</mi></mrow></munder><msubsup><mrow><mstyle mathvariant="bold"><mi>m</mi></mstyle></mrow><mrow><mi mathvariant="italic">ij</mi></mrow><mrow><mi>t</mi><mo class="MathClass-bin" stretchy="false">+</mo><mn>1</mn></mrow></msubsup><mo class="MathClass-close" stretchy="false">)</mo><mspace class="thinspace" width="0.17em"></mspace><mo class="MathClass-punc" stretchy="false">,</mo><mspace width="2em"></mspace></mtd>
<mtd class="align-label" columnalign="right"><mstyle class="label" id="x51-215002r2"></mstyle><!--  endlabel  --><mstyle class="maketag"><mtext>(10.1.2)</mtext></mstyle><mspace class="nbsp" width="0.33em"></mspace>
</mtd></mtr></mtable></math>
<!--  l. 77  --><p class="noindent">where <!--  l. 77  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow><mstyle mathvariant="bold"><mi>m</mi></mstyle></mrow><mrow><mi mathvariant="italic">ij</mi></mrow><mrow><mi>t</mi><mo class="MathClass-bin" stretchy="false">+</mo><mn>1</mn></mrow></msubsup></math> is the message
vector sent from particle <!--  l. 77  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mi>j</mi></math>
to particle <!--  l. 77  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mi>i</mi></math>,
<!--  l. 77  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow><mstyle mathvariant="bold"><mi>h</mi></mstyle></mrow><mrow><mi>i</mi></mrow><mrow><mi>t</mi><mo class="MathClass-bin" stretchy="false">+</mo><mn>1</mn></mrow></msubsup></math> are the updated
features of particle <!--  l. 77  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mi>i</mi></math>,
and <!--  l. 77  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow><mi>f</mi></mrow><mrow><mi>e</mi></mrow><mrow><mi>t</mi><mo class="MathClass-bin" stretchy="false">+</mo><mn>1</mn></mrow></msubsup></math>
                                                                                

                                                                                
and <!--  l. 77  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow><mi>f</mi></mrow><mrow><mi>n</mi></mrow><mrow><mi>t</mi><mo class="MathClass-bin" stretchy="false">+</mo><mn>1</mn></mrow></msubsup></math>
are arbitrary functions which, in our case, are implemented as multilayer perceptrons
(MLPs) with 3 FC layers.
</p><!--  l. 81  --><p class="noindent">
</p>
<h5 class="subsubsectionHead" id="generator"><a id="x51-216000"></a>Generator</h5>
<!--  l. 83  --><p class="noindent">We test two initializations of a particle cloud for the MPGAN generator: (1) directly initializing
the cloud with <!--  l. 83  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mi>N</mi></math>
particles, each with <!--  l. 83  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mi>L</mi></math>
randomly sampled features, which we refer to as the MP generator, and (2) inputting a single
<!--  l. 83  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mi>Z</mi></math>-dimensional
latent noise vector and transforming it via an FC layer into an
<!--  l. 83  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>N</mi> <mo class="MathClass-bin" stretchy="false">×</mo> <mi>L</mi></mrow></math>-dimensional
matrix, which we refer to as the MP-Latent-FC (MP-LFC) generator. MP-LFC uses a
latent space which can intuitively be understood as representing the initial source
particle’s features along with parameters to capture the stochasticity of the jet
production process. Due to the complex nature of this process, however, we
posit that this global, flattened latent space cannot capture the full phase
space of individual particle features. Hence, we introduce the MP generator,
                                                                                

                                                                                
which samples noise directly per particle, and find that it outperforms MP-LFC
(Table <a href="#six-evaluation-scores-on-different-generator-and-discriminator-combinations-lower-is-better-for-all-metrics-except-cov-">10.2<!--  tex4ht:ref: tab:04_mpgan_results   --></a>).
</p><!--  l. 88  --><p class="noindent">
</p>
<h5 class="subsubsectionHead" id="discriminator"><a id="x51-217000"></a>Discriminator</h5>
<!--  l. 90  --><p class="noindent">We find the MP generator, in conjunction with a PointNet discriminator, to be a
significant improvement on every metric compared to FC and GraphCNN generators.
However, the jet-level features are not yet reproduced to a high enough accuracy
(Section <a href="#x51-222000doc">10.1.4.<!--  tex4ht:ref: sec:04_mpgan_results   --></a>). While PointNet is able to capture global structural information, it can
miss the complex interparticle correlations in real particle clouds. We find we can
overcome this limitation by incorporating message passing in the discriminator as well
as in the generator. Concretely, our MP discriminator receives the real or generated
cloud and applies MP layers to produce intermediate features for each particle, which
are then aggregated via a feature-wise average-pooling operation and passed through an
FC layer to output the final scalar feature. We choose 2 MP layers for both
networks.
</p><!--  l. 97  --><p class="noindent">
</p>
<h5 class="subsubsectionHead" id="variablesized-clouds"><a id="x51-218000"></a>Variable-sized clouds</h5>
<!--  l. 99  --><p class="noindent">In order to handle clouds with varying numbers of particles, as typical of jets, we
introduce an additional binary “masking” particle feature classifying the particle as
genuine or zero-padded. Particles in the zero-padded class are ignored entirely in the
message passing and pooling operations. The MP generator adds mask features
to the initial particle cloud, using an additional input of the size of the jet
<!--  l. 101  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mi>N</mi></math>,
sampled from the real distribution per jet type, before the message passing layers, based
on sorting in particle feature space. Ablation studies with alternative (as well as
without) masking strategies are discussed in App. <span class="ec-lmbx-12">??</span>.
</p><!--  l. 104  --><p class="noindent">
</p>
<h4 class="subsectionHead" id="experiments-on-mnist-handwritten-digits"><span class="titlemark">10.1.3   </span> <a id="x51-21900010.1.3"></a>Experiments on MNIST handwritten digits</h4>
<!--  l. 107  --><p class="noindent">Before applying MPGAN to the <span class="small-caps">JetNet</span> dataset, we test it initially on point-cloud
versions of the MNIST handwritten digits dataset [<a href="Bibliography.html#Xdeng2012mnist">317</a>]. Practically, these were highly
useful during the development of the model, while exploring architectures,
hyperparameters, and training strategies, as they provided a simpler test-bench as well
                                                                                

                                                                                
as an easy way to visually evaluate the model.
</p><!--  l. 110  --><p class="indent">       We consider two MNIST datasets. First, a sparse graph representation of the
MNIST dataset, where from each image we select the 100 highest intensity pixels as the
nodes of a fully connected graph, with their feature vectors consisting of the
<!--  l. 111  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math>,
<!--  l. 111  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mi>y</mi></math>
coordinates and intensities. This is directly analogous to selecting the coordinates and
momenta of the highest momentum particles in a jet or highest energy hits in a
detector. The second dataset, known as the MNIST superpixels dataset [<a href="Bibliography.html#Xmonti2017geometric">316</a>], was
created by converting each MNIST image into 75 superpixels, corresponding to the
nodes of a graph. The centers and intensities of the superpixels comprise the hidden
features of the nodes.
</p><!--  l. 117  --><p class="indent">       We train MPGAN separately for each digit, analogous to independent
trainings for different jet classes. The best parameters per-digit are chosen using a
variation of FID adopted for point clouds, using the hidden features of the MoNet
classifier [<a href="Bibliography.html#Xmonti2017geometric">316</a>]. The comparison between the real and MPGAN-generated samples for
both datasets can be seen in Figure <a href="#samples-from-our-sparse-mnist-dataset-far-left-compared-to-samples-from-mpgan-center-left-samples-from-the-mnist-superpixels-dataset-center-right-compared-to-samples-from-mpgan-far-right">10.2<!--  tex4ht:ref: fig:04_mpgan_mnist   --></a>. We observe that the model is able
to reproduce the real samples with high fidelity and little evidence of mode
dropping.
</p>
<figure class="figure">
<!--  l. 124  --><p class="noindent" id="samples-from-our-sparse-mnist-dataset-far-left-compared-to-samples-from-mpgan-center-left-samples-from-the-mnist-superpixels-dataset-center-right-compared-to-samples-from-mpgan-far-right"> <img alt="PIC" src="figures/04-ML4Sim/mpgan/real_gen-.png" style="max-width:100%"/> <a id="x51-219001r2"></a>
</p>
<figcaption class="caption"><span class="id"><span class="ec-lmbx-12">Figure 10.2. </span></span><span class="content">Samples from our sparse MNIST dataset (far left) compared to
samples from MPGAN (center left). Samples from the MNIST superpixels dataset
(center right) compared to samples from MPGAN (far right).                    </span></figcaption><!--  tex4ht:label?: x51-219001r2   -->
</figure>
<h4 class="subsectionHead" id="experiments-on-jets"><span class="titlemark">10.1.4   </span> <a id="x51-22000010.1.4"></a>Experiments on jets</h4>
<!--  l. 133  --><p class="noindent">We now present results on the <span class="small-caps">JetNet</span> dataset. We first discuss the evaluation metrics,
then the results of the MPGAN model compared to several baseline point-cloud
generative models, as well as extensive discussion on both the architecture and
evaluation metric choices.
</p><!--  l. 136  --><p class="noindent">
</p>
<h5 class="subsubsectionHead" id="evaluation1"><a id="x51-221000"></a>Evaluation</h5>
<a id="x51-221000doc"></a>
<!--  l. 139  --><p class="noindent">We use four techniques discussed in Section <a href="#evaluation">10.1.1<!--  tex4ht:ref: sec:04_mpgan_geneval   --></a> for evaluating and
comparing models. Distributions of physical particle and jet features
are compared visually and quantitatively using the Wasserstein-1
(<!--  l. 140  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow><mi>W</mi></mrow><mrow><mn>1</mn></mrow></msub></math>) distance
between them. For ease of evaluation, we report (1) the average scores of the three particle
features (<!--  l. 141  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow><mi>W</mi></mrow><mrow><mn>1</mn></mrow><mrow><mstyle mathvariant="normal"><mi>P</mi></mstyle></mrow></msubsup></math>)
                                                                                

                                                                                
<!--  l. 141  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow><mi>η</mi></mrow><mrow><mstyle mathvariant="normal"><mi>rel</mi></mstyle></mrow></msup></math>,
<!--  l. 141  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow><mi>ϕ</mi></mrow><mrow><mstyle mathvariant="normal"><mi>rel</mi></mstyle></mrow></msup></math>, and
<!--  l. 141  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow><mi>p</mi></mrow><mrow><mstyle mathvariant="normal"><mi>T</mi></mstyle></mrow><mrow><mstyle mathvariant="normal"><mi>rel</mi></mstyle></mrow></msubsup></math>, (2) the jet mass
(<!--  l. 141  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow><mi>W</mi></mrow><mrow><mn>1</mn></mrow><mrow><mstyle mathvariant="normal"><mi>M</mi></mstyle></mrow></msubsup></math>), and (3) the average
of a subset of the EFPs<span class="footnote-mark"><a href="#fn51x11" id="fn51x11-bk"><sup class="textsuperscript">1</sup></a></span><a id="x51-221001f1"></a>
(<!--  l. 142  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow><mi>W</mi></mrow><mrow><mn>1</mn></mrow><mrow><mstyle mathvariant="normal"><mi>EFP</mi></mstyle></mrow></msubsup></math>),
which together provide a holistic picture of the low- and high-level aspects of a jet. The
<!--  l. 143  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow><mi>W</mi></mrow><mrow><mn>1</mn></mrow></msub></math>
distances are calculated for each feature between random samples of
10,000 real and generated jets, and averaged over 5 batches. Baseline
<!--  l. 144  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow><mi>W</mi></mrow><mrow><mn>1</mn></mrow></msub></math>
distances are calculated between two sets of randomly sampled real jets with 10,000
samples each, and are listed for each feature in Table <a href="#w-distances-between-real-jet-mass-w-m-averaged-particle-features-w-p-and-averaged-jet-efps-w-efp-distributions-calculated-as-a-baseline-for-three-classes-of-jets-">10.1<!--  tex4ht:ref: tab:04_mpgan_realw1   --></a>. The real samples are split
70/30 for training/evaluation. We train ParticleNet for classification on our dataset to
develop the FPND metric. FPND is calculated between 50,000 random real and
generated samples, based on the activations of the first FC layer in our trained
model<span class="footnote-mark"><a href="#fn52x11" id="fn52x11-bk"><sup class="textsuperscript">2</sup></a></span><a id="x51-221003f2"></a>.
Coverage and MMD are calculated between 100 real and 100 generated samples, and
averaged over 10 such batches. Implementations for all metrics are provided in the
<span class="small-caps">JetNet</span> package [<a href="Bibliography.html#Xjetnetlib">318</a>].
</p>
<div class="table">
<!--  l. 151  --><p class="indent"> </p><figure class="float" id="x51-221005r1"><span id="w-distances-between-real-jet-mass-w-m-averaged-particle-features-w-p-and-averaged-jet-efps-w-efp-distributions-calculated-as-a-baseline-for-three-classes-of-jets-"></span>
<figcaption class="caption"><span class="id"><span class="ec-lmbx-12">Table 10.1. </span></span><span class="content"><!--  l. 154  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow><mi>W</mi></mrow><mrow><mn>1</mn></mrow></msub></math>
distances between real jet mass (<!--  l. 154  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow><mi>W</mi></mrow><mrow><mn>1</mn></mrow><mrow><mstyle mathvariant="normal"><mi>M</mi></mstyle></mrow></msubsup></math>),
averaged particle features (<!--  l. 154  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow><mi>W</mi></mrow><mrow><mn>1</mn></mrow><mrow><mstyle mathvariant="normal"><mi>P</mi></mstyle></mrow></msubsup></math>),
and averaged jet EFPs (<!--  l. 154  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow><mi>W</mi></mrow><mrow><mn>1</mn></mrow><mrow><mstyle mathvariant="normal"><mi>EFP</mi></mstyle></mrow></msubsup></math>)
distributions calculated as a baseline, for three classes of jets.                    </span></figcaption><!--  tex4ht:label?: x51-221005r1   -->
<div class="pic-tabular">
<img alt="-------------------------------------------------------------

   Jet class   W M1  (×10 − 3)  W P1 (×10 −3)  W 1EFP (×10 −5)
-------------------------------------------------------------
    Gluon      0.7 ± 0.2      0.44 ± 0.09    0.62 ± 0.07

 Light quark   0.5 ± 0.1      0.5 ± 0.1     0.46 ± 0.04

  Top quark    0.51 ± 0.07     0.55 ± 0.07    1.1 ± 0.1
-------------------------------------------------------------
" src="main-ad61335697c619cede18473c171041a7.svg"/></div>
</figure>
</div>
<h5 class="subsubsectionHead" id="results"><a id="x51-222000"></a>Results</h5>
<a id="x51-222000doc"></a>
<!--  l. 169  --><p class="noindent">On each of <span class="small-caps">JetNet</span>’s three classes, we test r-GAN’s FC, GraphCNN, and TreeGAN
generators with rGAN’s FC and the PointNet-Mix discriminators, and compare them to
MPGAN’s MP generator and discriminator models, including both MP and MP-LFC
generator variations. Training and implementation details for each can be found in App. <span class="ec-lmbx-12">??</span>,
and all code in Ref. [<a href="Bibliography.html#Xmpgancode">319</a>]. We use a maximum of 30 particles per jet, choosing the 30
highest-<!--  l. 171  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow><mi>p</mi></mrow><mrow><mstyle mathvariant="normal"><mi>T</mi></mstyle></mrow></msub></math>
particles in jets with more than 30.
</p>
<figure class="figure" id="x51-222001r3"><span id="comparison-of-real-and-generated-distributions-for-a-subset-of-jet-and-particle-features"></span>
<div class="centerline"> <img alt="PIC" src="figures/04-ML4Sim/mpgan/results/feature_distributions-.png" style="max-width:100%"/> </div>
<figcaption class="caption"><span class="id"><span class="ec-lmbx-12">Figure 10.3.  </span></span><span class="content">Comparison  of  real  and  generated  distributions  for  a  subset  of
jet and particle features. We use the best performing model for each of the FC,
GraphCNN,  TreeGAN,  and  MP  generators,  as  per  Table <a href="#six-evaluation-scores-on-different-generator-and-discriminator-combinations-lower-is-better-for-all-metrics-except-cov-">10.2<!--  tex4ht:ref: tab:04_mpgan_results   --></a>.  Top:  gluon  jet
features, Middle: light quark jets, Bottom: top quark jets.                       </span></figcaption><!--  tex4ht:label?: x51-222001r3   -->
</figure>
<!--  l. 182  --><p class="indent">       We choose model parameters which, during training, yield the lowest
<!--  l. 182  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow><mi>W</mi></mrow><mrow><mn>1</mn></mrow><mrow><mstyle mathvariant="normal"><mi>M</mi></mstyle></mrow></msubsup></math> score. This
is because (1) <!--  l. 183  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow><mi>W</mi></mrow><mrow><mn>1</mn></mrow></msub></math>
scores between physical features are more relevant for physics applications than the
other three metrics, and (2) qualitatively we find it be a better discriminator of model
quality than particle features or EFP scores. Table <a href="#six-evaluation-scores-on-different-generator-and-discriminator-combinations-lower-is-better-for-all-metrics-except-cov-">10.2<!--  tex4ht:ref: tab:04_mpgan_results   --></a> lists the scores for each model
and class, and Figure <a href="#comparison-of-real-and-generated-distributions-for-a-subset-of-jet-and-particle-features">10.3<!--  tex4ht:ref: fig:04_mpgan_results   --></a> shows plots of selected feature distributions of real and
generated jets, for the best performing FC, GraphCNN, TreeGAN, and MP
generators. We also provide discretized images in the angular-coordinates-plane, a.k.a
“jet images”, in Figures <a href="#random-samples-of-discretized-images-in-the-rel-rel-plane-with-pixel-intensities-equal-to-particle-p-t-rel-of-real-and-generated-gluon-jets-left-and-an-average-over-such-sample-images-right">10.4<!--  tex4ht:ref: fig:04_mpgan_jetims_g   --></a>—<a href="#random-samples-of-discretized-images-in-the-rel-rel-plane-with-pixel-intensities-equal-to-particle-p-t-rel-of-real-and-generated-top-quark-jets-left-and-an-average-over-such-sample-images-right">10.6<!--  tex4ht:ref: fig:04_mpgan_jetims_t   --></a>; however, we note that it is in general
not easy to visually evaluate the quality of individual particle clouds, hence
we focus on metrics and visualizations aggregated over batches of clouds.
Overall we find that MPGAN is a significant improvement over the best FC,
GraphCNN, and TreeGAN models, particularly for top and light quark jets.
This is evident both visually and quantitatively in every metric, especially jet
<!--  l. 187  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow><mi>W</mi></mrow><mrow><mn>1</mn></mrow></msub></math>s and FPND, with
the exception of <!--  l. 187  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow><mi>W</mi></mrow><mrow><mn>1</mn></mrow><mrow><mstyle mathvariant="normal"><mi>P</mi></mstyle></mrow></msubsup></math>
where only the FC generator and PointNet discriminator (FC + PointNet) combination
is more performant.
</p>
<div class="table">
<!--  l. 189  --><p class="indent"> </p><figure class="float" id="x51-222002r2"><span id="six-evaluation-scores-on-different-generator-and-discriminator-combinations-lower-is-better-for-all-metrics-except-cov-"></span>
<figcaption class="caption"><span class="id"><span class="ec-lmbx-12">Table 10.2.  </span></span><span class="content">Six  evaluation  scores  on  different  generator  and  discriminator
combinations. Lower is better for all metrics except COV.
</span></figcaption><!--  tex4ht:label?: x51-222002r2   -->
<div class="pic-tabular"><img alt="----------------------------------------------------------------------------------------------------------
                                          W  M         W  P         W EFP
 Jet class  Generator     Discriminator        1           1            1        FPND     COV   ↑   MMD
                                          (×10 − 3)     (×10 − 3)     (×10 −5)
----------------------------------------------------------------------------------------------------------

           FC            FC               18.3 ± 0.2    9.6 ± 0.4     8.5 ± 0.5     176     0.24     0.045

           GraphCNN      FC               2.6 ± 0.2    9.6 ± 0.3      12 ± 8      61      0.39     0.046

           TreeGAN       FC               41.9 ± 0.3    69.3 ± 0.3   14.2 ± 0.8     355     0.19     0.130

           FC            PointNet         1.3 ± 0.4    1.3 ± 0.2     1.5 ± 0.9     5.0     0.49     0.039

           GraphCNN      PointNet         1.9 ± 0.2     16 ± 6    200 ±  1000    7k      0.46     0.040

           TreeGAN       PointNet         1.7 ± 0.1    4.0 ± 0.4      4 ± 1       84      0.37     0.042
           ---------------------------
  Gluon    MP            MP               0.7 ± 0.2    0.9 ± 0.3   0.7 ± 0.2    0.12     0.56     0.037

           MP  -LFC      MP             0.69 ±  0.07   1.8 ± 0.2     0.9 ± 0.6     0.20     0.54     0.037
           ---------------------------

           FC            MP               4.3 ± 0.3    21.1 ± 0.2     9 ± 1       368     0.11     0.085

           GraphCNN      MP               2.5 ± 0.1    9.8 ± 0.2      13 ± 8      61      0.38     0.048

           TreeGAN       MP               2.4 ± 0.2     12 ± 7       18 ± 9      69      0.34     0.048

           MP            FC               1.2 ± 0.2    3.7 ± 0.5     1.6 ± 0.8     39      0.44     0.040

           MP            PointNet         1.3 ± 0.4    1.2 ± 0.4      4 ± 2       18      0.53    0.036
----------------------------------------------------------------------------------------------------------
           FC            FC               6.0 ± 0.2    16.3 ± 0.9    3.9 ± 0.6     395     0.18     0.053

           GraphCNN      FC               3.5 ± 0.2    15.1 ± 0.4    10 ± 50      100     0.25     0.038

           TreeGAN       FC               31.5 ± 0.3    22.3 ± 0.4    9.3 ± 0.4     176     0.06     0.055

           FC            PointNet         3.1 ± 0.2    4.5 ± 0.4     2.3 ± 0.6     17      0.37     0.028

           GraphCNN      PointNet           4 ± 1      5.2 ± 0.5    50k ±100k     316     0.37     0.031

           TreeGAN       PointNet         10.1 ± 0.1    5.7 ± 0.5     4.1 ± 0.3     11      0.47     0.031
  Light    ---------------------------

  quark    MP            MP               0.6 ± 0.2    4.9 ± 0.5    0.7 ± 0.4     0.35     0.50     0.026

           MP  -LFC      MP               0.7 ± 0.2    2.6 ± 0.4    0.9 ± 0.9    0.08     0.52     0.024
           ---------------------------
           FC            MP               6.3 ± 0.2    16.5 ± 0.2    4.0 ± 0.8     212     0.11     0.070

           GraphCNN      MP               3.5 ± 0.4    15.0 ± 0.3    10 ± 10      99      0.26     0.038

           TreeGAN       MP               4.8 ± 0.2     33 ± 6       10 ± 2      148     0.22     0.041

           MP            FC               1.3 ± 0.1    4.5 ± 0.4     2.2 ± 0.6     41      0.37     0.030

           MP            PointNet         6.5 ± 0.3    23.2 ± 0.6     6 ± 1       850     0.18    0.034
----------------------------------------------------------------------------------------------------------

           FC            FC               4.8 ± 0.3    14.5 ± 0.6     23 ± 3      160     0.28     0.103

           GraphCNN      FC               7.0 ± 0.3    8.0 ± 0.5     1k ±6k       15      0.48     0.081

           TreeGAN       FC               17.0 ± 0.2    19.6 ± 0.6     33 ± 2      77      0.39     0.083

           FC            PointNet         2.7 ± 0.1    1.6 ± 0.4    7.7 ± 0.5     3.9     0.56     0.075

           GraphCNN      PointNet         11.3 ± 0.9     30 ± 10      37 ± 2      30k     0.39     0.085

           TreeGAN       PointNet        5.19 ± 0.08   9.1 ± 0.3      16 ± 2      17      0.53     0.079
  Top      ---------------------------
           MP            MP               0.6 ± 0.2    2.3 ± 0.3      2 ± 1      0.37     0.57     0.071
  quark
           MP  -LFC      MP               0.9 ± 0.3    2.2 ± 0.7      2 ± 1       0.93     0.56     0.073
           ---------------------------

           FC            MP               6.9 ± 0.1    39.1 ± 0.3     15 ± 1      81      0.26     0.120

           GraphCNN      MP               6.7 ± 0.1    8.2 ± 0.5     40 ± 10      15      0.49     0.081

           TreeGAN       MP               13.4 ± 0.4     45 ± 7      50 ± 30      66      0.29     0.101

           MP            FC               12.9 ± 0.3    26.3 ± 0.4     46 ± 3      58      0.27     0.103

           MP            PointNet        0.76 ± 0.08   1.6 ± 0.4     4 ± 1       3.7     0.59    0.072
----------------------------------------------------------------------------------------------------------" src="main-59f8dc9318c93c8c69c4c33b186a2e6c.svg"/></div>
</figure>
</div>
<figure class="figure" id="x51-222003r4"><span id="random-samples-of-discretized-images-in-the-rel-rel-plane-with-pixel-intensities-equal-to-particle-p-t-rel-of-real-and-generated-gluon-jets-left-and-an-average-over-such-sample-images-right"></span>
<div class="centerline"> <img alt="PIC" src="figures/04-ML4Sim/mpgan/results/jet_images_g-.png" style="max-width:100%"/> </div>
<figcaption class="caption"><span class="id"><span class="ec-lmbx-12">Figure 10.4.     </span></span><span class="content">Random     samples     of     discretized     images     in     the
<!--  l. 219  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow><mi>η</mi></mrow><mrow><mstyle mathvariant="normal"><mi>rel</mi></mstyle></mrow></msup></math>
<!--  l. 219  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mo class="MathClass-bin" stretchy="false">−</mo></math><!--  l. 219  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow><mi>ϕ</mi></mrow><mrow><mstyle mathvariant="normal"><mi>rel</mi></mstyle></mrow></msup></math>
plane,         with         pixel         intensities         equal         to         particle
<!--  l. 219  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow><mi>p</mi></mrow><mrow><mstyle mathvariant="normal"><mi>T</mi></mstyle></mrow><mrow><mstyle mathvariant="normal"><mi>rel</mi></mstyle></mrow></msubsup></math>,
of real and generated gluon jets (left), and an average over 10,000 such sample
images (right).                                                                 </span></figcaption><!--  tex4ht:label?: x51-222003r4   -->
</figure>
<figure class="figure" id="x51-222004r5"><span id="random-samples-of-discretized-images-in-the-rel-rel-plane-with-pixel-intensities-equal-to-particle-p-t-rel-of-real-and-generated-light-quark-jets-left-and-an-average-over-such-sample-images-right"></span>
<div class="centerline"> <img alt="PIC" src="figures/04-ML4Sim/mpgan/results/jet_images_q-.png" style="max-width:100%"/> </div>
<figcaption class="caption"><span class="id"><span class="ec-lmbx-12">Figure 10.5.     </span></span><span class="content">Random     samples     of     discretized     images     in     the
<!--  l. 226  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow><mi>η</mi></mrow><mrow><mstyle mathvariant="normal"><mi>rel</mi></mstyle></mrow></msup></math>
<!--  l. 226  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mo class="MathClass-bin" stretchy="false">−</mo></math><!--  l. 226  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow><mi>ϕ</mi></mrow><mrow><mstyle mathvariant="normal"><mi>rel</mi></mstyle></mrow></msup></math>
plane,         with         pixel         intensities         equal         to         particle
<!--  l. 226  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow><mi>p</mi></mrow><mrow><mstyle mathvariant="normal"><mi>T</mi></mstyle></mrow><mrow><mstyle mathvariant="normal"><mi>rel</mi></mstyle></mrow></msubsup></math>,
of  real  and  generated  light  quark  jets  (left),  and  an  average  over  10,000  such
sample images (right).                                                          </span></figcaption><!--  tex4ht:label?: x51-222004r5   -->
</figure>
<figure class="figure" id="x51-222005r6"><span id="random-samples-of-discretized-images-in-the-rel-rel-plane-with-pixel-intensities-equal-to-particle-p-t-rel-of-real-and-generated-top-quark-jets-left-and-an-average-over-such-sample-images-right"></span>
<div class="centerline"> <img alt="PIC" src="figures/04-ML4Sim/mpgan/results/jet_images_t-.png" style="max-width:100%"/> </div>
<figcaption class="caption"><span class="id"><span class="ec-lmbx-12">Figure 10.6.     </span></span><span class="content">Random     samples     of     discretized     images     in     the
<!--  l. 233  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow><mi>η</mi></mrow><mrow><mstyle mathvariant="normal"><mi>rel</mi></mstyle></mrow></msup></math>
<!--  l. 233  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mo class="MathClass-bin" stretchy="false">−</mo></math><!--  l. 233  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow><mi>ϕ</mi></mrow><mrow><mstyle mathvariant="normal"><mi>rel</mi></mstyle></mrow></msup></math>
plane,         with         pixel         intensities         equal         to         particle
<!--  l. 233  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow><mi>p</mi></mrow><mrow><mstyle mathvariant="normal"><mi>T</mi></mstyle></mrow><mrow><mstyle mathvariant="normal"><mi>rel</mi></mstyle></mrow></msubsup></math>,
of real and generated top quark jets (left), and an average over 10,000 such sample
images (right).                                                                 </span></figcaption><!--  tex4ht:label?: x51-222005r6   -->
</figure>
<!--  l. 237  --><p class="indent">       We additionally perform a latency measurement and find,
using an NVIDIA A100 GPU, that MPGAN generation requires
<!--  l. 237  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mn>35</mn><mo class="MathClass-punc" stretchy="false">.</mo><mn>7</mn><mi>μ</mi></mrow></math>s per
jet. In comparison, the traditional generation process for <span class="small-caps">JetNet</span> is measured on
an 8-CPU machine as requiring 46ms per jet, meaning MPGAN provides a
three-orders-of-magnitude speed-up. Furthermore, as noted in Section <a href="JetNet.html#jetnet">9.2<!--  tex4ht:ref: sec:04_jetnet_dataset   --></a>, the
generation of <span class="small-caps">JetNet</span> is significantly simpler than full simulation and reconstruction
used at the LHC, which has been measured to require 12.3s [<a href="Bibliography.html#XPedro_2018jqu">302</a>] and 4s [<a href="Bibliography.html#Xchen2020data">320</a>]
respectively per top quark jet. Hence in practical applications we anticipate MPGAN’s
improvement to potentially rise to five-orders-of-magnitude.
</p>
<h5 class="subsubsectionHead" id="real-baseline-comparison"><a id="x51-223000"></a>Real baseline comparison</h5>
<!--  l. 245  --><p class="noindent">We find that MPGAN’s jet-level <!--  l. 245  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow><mi>W</mi></mrow><mrow><mn>1</mn></mrow></msub></math>
scores all fall within error of the baselines in Table <a href="#w-distances-between-real-jet-mass-w-m-averaged-particle-features-w-p-and-averaged-jet-efps-w-efp-distributions-calculated-as-a-baseline-for-three-classes-of-jets-">10.1<!--  tex4ht:ref: tab:04_mpgan_realw1   --></a>, while those of alternative
generators are several standard deviations away. This is particularly an issue with
complex top quark particle clouds, where we can see in Figure <a href="#comparison-of-real-and-generated-distributions-for-a-subset-of-jet-and-particle-features">10.3<!--  tex4ht:ref: fig:04_mpgan_results   --></a> none of the existing
generators are able to learn the bimodal jet feature distributions, and smaller
light quark clouds, where we see distortion of jet features due to difficulty
                                                                                

                                                                                
reproducing the zero-padded particle features. No model is able to achieve
particle-level scores close to the baseline, and only those of the FC + PointNet
combination and MPGAN are of the same order of magnitude. We conclude
that MPGAN reproduces the physical observable distributions to the highest
degree of accuracy, but note, however, that it requires further improvement in
particle feature reconstruction before it is ready for practical application in
HEP.
</p><!--  l. 251  --><p class="noindent">
</p>
<h5 class="subsubsectionHead" id="architecture-discussion"><a id="x51-224000"></a>Architecture discussion</h5>
<!--  l. 253  --><p class="noindent">To disentangle the effectiveness of the MP generator and discriminator, we train
each individually with alternative counterparts (Table <a href="#six-evaluation-scores-on-different-generator-and-discriminator-combinations-lower-is-better-for-all-metrics-except-cov-">10.2<!--  tex4ht:ref: tab:04_mpgan_results   --></a>). With the same
PointNet discriminator, the GraphCNN and TreeGAN generators perform
worse than the simple FC generator for every metric on all three datasets.
The physics-motivated MP generator on the other hand outperforms all
on the gluon and top quark datasets, and significantly so on the jet-level
<!--  l. 255  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow><mi>W</mi></mrow><mrow><mn>1</mn></mrow></msub></math>
scores and the FPND. We note, however, that the MP generator is not a
significant improvement over the other generators with an FC discriminator.
                                                                                

                                                                                
Holding the generator fixed, the PointNet discriminator performs significantly
better over the FC for all metrics. With the FC, GraphCNN, and TreeGAN
generators, PointNet is also an improvement over the MP discriminator. With
an MP generator, the MP discrimimator is more performant on jet-level
<!--  l. 259  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow><mi>W</mi></mrow><mrow><mn>1</mn></mrow></msub></math>
and FPND scores but, on the top quark dataset, degrades
<!--  l. 259  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow><mi>W</mi></mrow><mrow><mn>1</mn></mrow><mrow><mstyle mathvariant="normal"><mi>P</mi></mstyle></mrow></msubsup></math>
relative to PointNet.
</p><!--  l. 261  --><p class="indent">       We learn from these three things: (1) a generator or discriminator architecture is
only as effective as its counterpart—even though the MPGAN combination is the best
overall, when paired with a network which is not able to learn complex substructure, or
which breaks the permutation symmetry, neither the generator or discriminator is
performant, (2) for high-fidelity jet feature reconstruction, both networks must be able
to learn complex multi-particle correlations—however, this can come at the cost
of low-level feature accuracy, and (3) MPGAN’s masking strategy is highly
effective as both MP networks are improvements all around on light quark
jets.
</p><!--  l. 264  --><p class="noindent">
</p>
<h5 class="subsubsectionHead" id="particle-cloud-evaluation-metrics"><a id="x51-225000"></a>Particle cloud evaluation metrics</h5>
<figure class="figure" id="x51-225001r7"><span id="correlation-plots-between-pairs-of-evaluation-metrics-evaluated-on-separate-batches-of-mpgan-generated-top-quark-jets-"></span>
<div class="centerline"> <img alt="PIC" src="figures/04-ML4Sim/mpgan/correlation_plots-.png" style="max-width:100%"/> </div>
<figcaption class="caption"><span class="id"><span class="ec-lmbx-12">Figure 10.7. </span></span><span class="content">Correlation plots between pairs of evaluation metrics, evaluated on
400 separate batches of 50,000 MPGAN generated top quark jets.               </span></figcaption><!--  tex4ht:label?: x51-225001r7   -->
</figure>
<!--  l. 275  --><p class="indent">       We now discuss the merits of each evaluation metrics and provide suggestions for
their use in future work. Figure <a href="#correlation-plots-between-pairs-of-evaluation-metrics-evaluated-on-separate-batches-of-mpgan-generated-top-quark-jets-">10.7<!--  tex4ht:ref: fig:04_mpgan_correlation   --></a> shows correlation plots between chosen pairs of our
evaluation metrics. As expected, we find W1-M and W1-EFP to be highly
correlated, as they both measure learning of global jet features. For rigorous
validation we suggest measuring both but for time-sensitive use-cases, such as
quick evaluations during model training, W1-M should be sufficient. W1-M,
FPND, and W1-P are all measuring different aspects of the generation and
are relatively uncorrelated. We expect FPND overall to be the best and most
discriminatory metric for evaluation, as it compares features found by a SOTA classifier
to be statistically optimum for characterizing jets, while the W1 scores are
valuable for their interpretability. Out of these, W1-M/W1-EFP are the most
important from a physics-standpoint, as we generally characterize collisions by
the high-level features of the output jets, rather than the individual particle
features.
</p><!--  l. 282  --><p class="indent">       MMD and coverage are both valuable for specifically evaluating
the quality and diversity of samples respectively, however we see from
Figure <a href="#correlation-plots-between-pairs-of-evaluation-metrics-evaluated-on-separate-batches-of-mpgan-generated-top-quark-jets-">10.7<!--  tex4ht:ref: fig:04_mpgan_correlation   --></a> that they saturate after a certain point, after which FPND and
<!--  l. 282  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow><mi>W</mi></mrow><mrow><mn>1</mn></mrow></msub></math> scores
are necessary for stronger discrimination. We also note that in Table <a href="#six-evaluation-scores-on-different-generator-and-discriminator-combinations-lower-is-better-for-all-metrics-except-cov-">10.2<!--  tex4ht:ref: tab:04_mpgan_results   --></a>, models with low
<!--  l. 283  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow><mi>W</mi></mrow><mrow><mn>1</mn></mrow></msub></math> scores
relative to the baseline have the best coverage and MMD scores as well. This indicates that
                                                                                

                                                                                
the <!--  l. 284  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow><mi>W</mi></mrow><mrow><mn>1</mn></mrow></msub></math>
metrics are sensitive to both mode collapse (measured by coverage), which is expected as in
terms of feature distributions mode collapse manifests as differing supports, to which
the <!--  l. 284  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow><mi>W</mi></mrow><mrow><mn>1</mn></mrow></msub></math>
distance is sensitive, as well as to individual sample quality (measured by MMD),
which supports our claim that recovering jet feature distributions implies
accurate learning of individual cloud structure. Together this suggests that low
<!--  l. 285  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow><mi>W</mi></mrow><mrow><mn>1</mn></mrow></msub></math>
scores are able to validate sample quality and against mode collapse,
and justifies our criteria that a practical ML simulation alternative have
<!--  l. 285  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow><mi>W</mi></mrow><mrow><mn>1</mn></mrow></msub></math> scores
close to the baselines in Table <a href="#six-evaluation-scores-on-different-generator-and-discriminator-combinations-lower-is-better-for-all-metrics-except-cov-">10.2<!--  tex4ht:ref: tab:04_mpgan_results   --></a>. In conclusion, for thorough validation of generated
particle clouds, we recommend considering all three W-1 scores in conjunction
with FPND, while MMD and coverage, being focused tests of these aspects
of generation, may be useful for understanding failure modes during model
development.
</p>
<h4 class="subsectionHead" id="summary2"><span class="titlemark">10.1.5   </span> <a id="x51-22600010.1.5"></a>Summary</h4>
<!--  l. 292  --><p class="noindent">In this section, we applied existing state-of-the-art point cloud generative models to
<span class="small-caps">JetNet</span>, and proposed several physics- and computer-vision-inspired metrics to
                                                                                

                                                                                
rigorously evaluate generated clouds. We found that existing models are not performant
on a number of metrics, and failed to reproduce high-level jet features—arguably the
most significant aspect for HEP. We then introduced the novel message-passing
generative adversarial network (MPGAN) model, designed to capture complex global
structure and handle variable-sized clouds, which significantly improved performance in
this area, as well as other metrics.
</p><!--  l. 296  --><p class="indent">       Despite the high performance, the major limitation of MPGAN is the quadratic
scaling of the message passing operation, which makes it difficult to scale to larger
clouds than 30-particle ones used in Section <a href="#experiments-on-jets">10.1.4<!--  tex4ht:ref: sec:04_mpgan_exp   --></a>. In the next section, we discuss the
iGAPT model to overcome this limitation.
                                                                                

                                                                                
</p>
<nav class="crosslinks-bottom"> <a href="Generativemodelsforfastparticlecloudsimulations.html">⭠</a> <a href="Generativeadversarialparticletransformers.html">⭢</a> </nav> <div class="footnotes"><a id="x51-221002x"></a>
<!--  l. 141  --><p class="indent"> <span class="footnote-mark"><a href="#fn51x11-bk" id="fn51x11"><sup class="textsuperscript">1</sup></a></span><span class="ec-lmr-10">We choose 5 EFPs corresponding to the set of loopless multigraphs with 4 vertices and 4
edges.</span></p><a id="x51-221004x"></a>
<!--  l. 147  --><p class="indent"> <span class="footnote-mark"><a href="#fn52x11-bk" id="fn52x11"><sup class="textsuperscript">2</sup></a></span><span class="ec-lmr-10">ParticleNet training details are given in App. </span><span class="ec-lmbx-10">??</span><span class="ec-lmr-10">. The trained model is provided in the
</span><span class="small-caps">JetNet </span><span class="ec-lmr-10">library [</span><a href="Bibliography.html#Xjetnetlib"><span class="ec-lmr-10">318</span></a><span class="ec-lmr-10">].</span></p> </div><div class="footer"><p>Copyright © 2024 Raghav Kansal. All rights reserved.</p></div></main>
</body>
</html>