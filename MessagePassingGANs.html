<!DOCTYPE html>

<html lang="en-US" xml:lang="en-US">
<head><title>Message Passing GANs</title>
<meta charset="utf-8"/>
<meta content="TeX4ht (https://tug.org/tex4ht/)" name="generator"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<link href="main.css" rel="stylesheet" type="text/css"/>
<meta content="main.tex" name="src"/>
<script async="async" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/mml-chtml.js" type="text/javascript"></script>
<link href="style.css" rel="stylesheet" type="text/css"/>
<link href="assets/icon.png" rel="icon" type="image/x-icon"/>
</head><body>
<nav class="TOC"><span class="mainToc"><a href="index.html"><img alt="Symmetries, QFT, &amp; The Standard Model" class="mainTocLogo" src="assets/logo.png" width="100%"/></a></span>
<span class="likepartToc"><a href="Frontmatter.html#front-matter">Front matter</a></span>
<span class="likepartToc"><a href="AbstractoftheDissertation.html#abstract-of-the-dissertation">Abstract of the Dissertation</a></span>
<span class="likepartToc"><a href="Introduction.html#introduction">Introduction</a></span>
<span class="partToc">I  <a href="TheoreticalBackground.html#theoretical-background">Theoretical Background</a></span>
<span class="partToc">II  <a href="ExperimentalBackground.html#experimental-background">Experimental Background</a></span>
<span class="partToc">III  <a href="AIMLandStatisticsBackground.html#aiml-and-statistics-background">AI/ML and Statistics Background</a></span>
<span class="partToc">IV  <a href="AcceleratingSimulationswithAI.html#accelerating-simulations-with-ai">Accelerating Simulations with AI</a></span>
<span class="partToc">V  <a href="SearchesforHighEnergyHiggsBosonPairs.html#searches-for-high-energy-higgs-boson-pairs">Searches for High Energy Higgs Boson Pairs</a></span>
<span class="partToc">VI  <a href="AIforJets.html#ai-for-jets">AI for Jets</a></span>
<span class="partToc">VII  <a href="Appendix.html#appendix">Appendix</a></span>
<span class="appendixToc">A <a href="SupplementaryMaterialforChapterrefsec01symmetries.html#supplementary-material-for-chapterref-secsymmetries">Supplementary Material for Chapter 2</a></span>
<span class="appendixToc">B <a href="SupplementaryMaterialforChapterrefsec01qft.html#supplementary-material-for-chapterref-secqft">Supplementary Material for Chapter 3</a></span>
<span class="appendixToc">C <a href="SupplementaryMaterialforChapterrefsec04models.html#supplementary-material-for-chapterref-secmodels">Supplementary Material for Chapter 10</a></span>
<span class="sectionToc">C.1 <a href="#message-passing-gans1">Message Passing GANs</a></span>
<span class="subsectionToc">C.1.1 <a href="#point-cloud-generative-models">Point Cloud Generative Models</a></span>
<span class="subsectionToc">C.1.2 <a href="#training-and-implementation-details">Training and Implementation Details</a></span>
<span class="subsectionToc">C.1.3 <a href="#masking-strategies">Masking Strategies</a></span>
<span class="sectionToc">C.2 <a href="GenerativeAdversarialParticleTransformers.html#generative-adversarial-particle-transformers1">Generative Adversarial Particle Transformers</a></span>
<span class="appendixToc">D <a href="SupplementaryMaterialforChapterrefsec04evaluating.html#supplementary-material-for-chapterref-secevaluating">Supplementary Material for Chapter 11</a></span>
<span class="appendixToc">E <a href="SupplementaryMaterialforChapterrefsec06lgae.html#supplementary-material-for-chapterref-seclgae">Supplementary Material for Chapter 16</a></span>
<span class="likepartToc"><a href="Bibliography.html#bibliography">Bibliography</a></span>
</nav>
<main class="main-content"><a class="header-link" href="https://github.com/rkansal47/dissertation" rel="noopener noreferrer" style="top: 10px; right: 12px;" target="_blank"><img alt="GitHub Repository" class="header-icon" src="https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png" style="width: 32px; height: 32px;"/></a><a class="header-link" href="https://github.com/rkansal47/dissertation/blob/gh-pages/dissertation.pdf?raw=true" rel="noopener noreferrer" style="top: 12px; right: 54px;" target="_blank"><img alt="Download PDF" class="header-icon" src="assets/download.png" style="width: 25px; height: 25px;"/></a>
<nav class="crosslinks-top"> <a href="SupplementaryMaterialforChapterrefsec04models.html">⭠</a> <a href="GenerativeAdversarialParticleTransformers.html">⭢</a> </nav>
<h3 class="sectionHead" id="message-passing-gans1"><span class="titlemark">C.1   </span> <a id="x91-351000C.1"></a>Message Passing GANs</h3>
<!--  l. 7  --><p class="noindent">
</p>
<h4 class="subsectionHead" id="point-cloud-generative-models"><span class="titlemark">C.1.1   </span> <a id="x91-352000C.1.1"></a>Point Cloud Generative Models</h4>
<figure class="figure" id="x91-352001r1"><span id="comparison-of-real-and-pcgangenerated-distributions-for-a-subset-of-jet-and-particle-features-top-gluon-jet-features-middle-light-quark-jets-bottom-top-quark-jets"></span>
<div class="centerline"> <img alt="PIC" src="figures/04-ML4Sim/mpgan/results/pcgan_feature_distributions-.png" style="max-width:100%"/> </div>
<figcaption class="caption"><span class="id"><span class="ec-lmbx-12">Figure C.1. </span></span><span class="content">Comparison of real and PCGAN-generated distributions for a subset
of  jet  and  particle  features.  Top:  gluon  jet  features,  Middle:  light  quark  jets,
Bottom: top quark jets.                                                         </span></figcaption><!--  tex4ht:label?: x91-352001r1   -->
</figure>
<h5 class="subsubsectionHead" id="shapenet-point-clouds"><a id="x91-353000"></a>ShapeNet Point Clouds</h5>
<!--  l. 18  --><p class="noindent">A number of successful generative models exploit a key inductive bias of ShapeNet-based
clouds: that the individual distributions of sampled points conditioned on a particular
object are identical and independent (the i.i.d assumption). This assumption allows for
hierarchical generative frameworks, such as Point-Cloud-GAN (PCGAN) [<a href="Bibliography.html#Xpcgan">283</a>], which
uses two networks: one to generate a latent object-level representation, and a second to
sample independent points given such a representation. The PointFlow [<a href="Bibliography.html#Xpointflow">284</a>] and
Discrete PointFlow [<a href="Bibliography.html#Xdiscretepointflow">285</a>] models use a similar idea of sampling independently points
conditioned on a learned latent representation of the shape, but with a variational
autoencoder (VAE) framework and using normalizing flows for transforming the
sampled points.
</p><!--  l. 22  --><p class="indent">       This hierarchical-sampling approach is appealing for ShapeNet clouds, however,
as discussed in Chapter <a href="Autoencodersandgenerativemodels.html#previous-work">7.3.3<!--  tex4ht:ref: sec:04_mpgan_genhep   --></a> the key i.i.d. assumption is not applicable to jets with
their highly correlated particle constituents. In fact, in contrast to ShapeNet objects
which have a structure independent of the particular sampled cloud, jets are entirely
defined by the distribution of their constituents.
</p><!--  l. 25  --><p class="indent">       Another model, ShapeGF [<a href="Bibliography.html#XShapeGF">286</a>], uses an approach of again sampling points
independently from a prior distribution, but transforming them to areas of high density
                                                                                

                                                                                
via gradient ascent, maximizing a learned log-density concentrated on an object’s
surface. This approach suffers as well from the i.i.d. assumption in the context of jets,
and additionally, unlike for ShapeNet point clouds, there is no such high-density region
in momentum-space where particles tend to be concentrated, so learning and
maximizing a log-density is not straightforward.
</p><!--  l. 28  --><p class="indent">       To support our overall claim of the inviability of the i.i.d. assumption for particle
clouds, we train a PCGAN model on <span class="small-caps">JetNet</span> and show the produced feature
distributions in Figure <a href="#comparison-of-real-and-pcgangenerated-distributions-for-a-subset-of-jet-and-particle-features-top-gluon-jet-features-middle-light-quark-jets-bottom-top-quark-jets">C.1<!--  tex4ht:ref: fig:04_mpgan_pcgan_results   --></a>. We can see that, as expected, while this network is partially
reproducing the particle feature distributions, it is entirely unable to learn the jet-level
structure in particle clouds.
</p><!--  l. 31  --><p class="noindent">
</p>
<h5 class="subsubsectionHead" id="molecular-point-clouds"><a id="x91-354000"></a>Molecular Point Clouds</h5>
<!--  l. 33  --><p class="noindent">3D molecules are another common point-cloud-style data structure, and there have been
developments in generative models in this area as well. Kohler et al. [<a href="Bibliography.html#Xkohler20">287</a>] introduce
physics-motivated normalizing flows equivariant to rotations around the center of mass,
i.e. the SO(N) symmetries, for generating point clouds. This is appealing as
normalizing flows give access to the explicit likelihood of generated samples,
and having an architecture equivariant to physical symmetries such as 3D
                                                                                

                                                                                
rotations can improve the generalizability and interpretability of the model. Since
jets are relativistic, however, we require an architecture equivariant to the
non-compact SO(3, 1) Lorentz group, to which this model has not been generalized
yet. Simm et al. [<a href="Bibliography.html#Xsimm21">288</a>] present a reinforcement-learning-based approach for
generating 3D molecules, using an agent to iteratively add atoms to a molecule
and defining the reward function as the energy difference between the new
molecule and the old with the new atom at the origin. This reward function is
not directly applicable to jets. where particle distributions are based on the
QCD dynamics rather than on minimizing the total energy. Finally, Gebauer et
al. [<a href="Bibliography.html#Xgschnet">289</a>] introduce G-SchNet, an autoregressive model for producing molecules
represented as point clouds, iteratively adding one atom at a time based on the
existing molecule. Their iterative procedure however was proposed for point
clouds of at most nine atoms, and does not scale well in terms of time to larger
clouds.
</p><!--  l. 42  --><p class="indent">       Overall, all the models discussed heavily incorporate inductive biases which are
specific to their respective datasets and don’t apply to JetNet. However, they are
extremely interesting approaches nonetheless, and adapting them with jet-motivated
biases should certainly be explored in future work. Indeed, a significant contribution of
our work is publishing a dataset which can facilitate and hopes to motivate such
development.
                                                                                

                                                                                
</p><!--  l. 46  --><p class="noindent">
</p>
<h4 class="subsectionHead" id="training-and-implementation-details"><span class="titlemark">C.1.2   </span> <a id="x91-355000C.1.2"></a>Training and Implementation Details</h4>
<!--  l. 49  --><p class="noindent">PyTorch code and trained parameters for models in Table <a href="MessagepassingGANs.html#six-evaluation-scores-on-different-generator-and-discriminator-combinations-lower-is-better-for-all-metrics-except-cov-">10.2<!--  tex4ht:ref: tab:04_mpgan_results   --></a> are provided
in the MPGAN repository [<a href="Bibliography.html#Xmpgancode">321</a>]. Models were trained and hyperparameters
optimized on clusters of NVIDIA GeForce RTX 2080 Ti, Tesla V100, and A100
GPUs.
</p><!--  l. 52  --><p class="noindent">
</p>
<h5 class="subsubsectionHead" id="mpgan"><a id="x91-356000"></a>MPGAN</h5>
<!--  l. 54  --><p class="noindent">We use the least squares loss function [<a href="Bibliography.html#Xmao_lsgan">325</a>] and the RMSProp optimizer with a two
time-scale update rule [<a href="Bibliography.html#XTTUR">315</a>] with a learning rate (LR) for the discriminator
three times greater than that of the generator. The absolute rate differed per
jet type. We use LeakyReLU activations (with negative slope coefficient 0.2)
after all MLP layers except for the final generator and discriminator outputs
where tanh and sigmoid activations respectively are applied. We attempted
discriminator regularization to alleviate mode collapse via dropout [<a href="Bibliography.html#Xsrivastava2014dropout">215</a>], batch
normalization [<a href="Bibliography.html#Xioffe2015batch">216</a>], a gradient penalty [<a href="Bibliography.html#Xwgangp">436</a>], spectral normalization [<a href="Bibliography.html#Xspectralnorm">437</a>], adaptive
                                                                                

                                                                                
competitive gradient descent [<a href="Bibliography.html#Xacgd">438</a>] and data augmentation of real and generated
graphs before the discriminator [<a href="Bibliography.html#Xkarras_2020">439</a>–<a href="Bibliography.html#Xzhao_2020">441</a>]. Apart from dropout (with fraction
<!--  l. 57  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mn>0.5</mn></mrow></math>), none
of these demonstrated significant improvement with respect to mode dropping or cloud
quality.
</p><!--  l. 59  --><p class="indent">       We use a generator LR of <!--  l. 59  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mn>1</mn><msup><mrow><mn>0</mn></mrow><mrow><mo class="MathClass-bin" stretchy="false">−</mo><mn>3</mn></mrow></msup></mrow></math>
and train for 2000 epochs for gluon jets,
<!--  l. 59  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mn>2</mn> <mo class="MathClass-bin" stretchy="false">×</mo> <mn>1</mn><msup><mrow><mn>0</mn></mrow><mrow><mo class="MathClass-bin" stretchy="false">−</mo><mn>3</mn></mrow></msup></mrow></math> and 2000 epochs for
top quark jets, and <!--  l. 59  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mn>0.5</mn> <mo class="MathClass-bin" stretchy="false">×</mo> <mn>1</mn><msup><mrow><mn>0</mn></mrow><mrow><mo class="MathClass-bin" stretchy="false">−</mo><mn>3</mn></mrow></msup></mrow></math>
and 2500 epochs for light quark jets. We use a batch size of 256 for all jets.
</p><!--  l. 62  --><p class="noindent">
</p>
<h5 class="subsubsectionHead" id="rgan-graphcnngan-treegan-and-pointnetmix"><a id="x91-357000"></a>rGAN, GraphCNNGAN, TreeGAN, and PointNet-Mix</h5>
<!--  l. 64  --><p class="noindent">For rGAN and GraphCNNGAN we train two variants: (1) using the original
architecture hyperparameters in Refs. [<a href="Bibliography.html#Xrgan">290</a>, <a href="Bibliography.html#Xgraphcnngan">291</a>] for the 2048-node point clouds, and (2)
using hyperparameters scaled down to 30-node clouds—specifically: a 32 dimensional
latent space, followed by layers of 64, 128, and 90 nodes for r-GAN, or followed by two
graph convolutional layers with node features sizes of 32 and 24 respectively for
GraphCNN-GAN. The scaled-down variant performed better for both models, and its
                                                                                

                                                                                
scores are the ones reported in Table <a href="MessagepassingGANs.html#six-evaluation-scores-on-different-generator-and-discriminator-combinations-lower-is-better-for-all-metrics-except-cov-">10.2<!--  tex4ht:ref: tab:04_mpgan_results   --></a>. For TreeGAN, starting from single
vertex—in analogy with a jet originating from a single particle—we use five layers of
up-sampling and ancestor-descendant message passing, with a scale-factor of two in each
and node features per layer of 96, 64, 64, 64, and 64 respectively. LRs, batch
sizes, loss functions, gradient penalties, optimizers, ratios of critic to generator
updates, activations, and number of epochs are the same as in the original
paper and code. We use the architecture defined in [<a href="Bibliography.html#Xwang2020rethinking">294</a>] for the PointNet-Mix
discriminator.
</p><!--  l. 70  --><p class="noindent">
</p>
<h5 class="subsubsectionHead" id="fpnd"><a id="x91-358000"></a>FPND</h5>
<a id="x91-358000doc"></a>
<!--  l. 73  --><p class="noindent">Apart from the number of input particle features (three in our case, excluding the mask feature),
we use the original ParticleNet architecture in Ref. [<a href="Bibliography.html#XQu_2019gqs">227</a>]. We find training with the Adam
optimizer, LR <!--  l. 74  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mn>1</mn><msup><mrow><mn>0</mn></mrow><mrow><mo class="MathClass-bin" stretchy="false">−</mo><mn>4</mn></mrow></msup></mrow></math>,
for 30 epochs outperformed the original recommendations on our dataset. Activations
after the first fully connected layer, pre-ReLU, are used for the FPND measurement.
                                                                                

                                                                                
</p><!--  l. 77  --><p class="noindent">
</p>
<h5 class="subsubsectionHead" id="pcgan"><a id="x91-359000"></a>PCGAN</h5>
<a id="x91-359000doc"></a>
<!--  l. 80  --><p class="noindent">We use the original PCGAN implementation for the sampling networks and training,
with a 256-dimensional latent object representation. For the latent code GAN we use a 3
layer fully connected network for both the generator, with an input size of 128 and
intermediate layer sizes of 256 and 512, and discriminator, with intermediate layer sizes
of 512 and 256, trained using the Wasserstein-GAN [<a href="Bibliography.html#XWGAN">442</a>] loss with a gradient
penalty.
</p><!--  l. 84  --><p class="noindent">
</p>
<h4 class="subsectionHead" id="masking-strategies"><span class="titlemark">C.1.3   </span> <a id="x91-360000C.1.3"></a>Masking Strategies</h4>
<figure class="figure" id="x91-360001r2"><span id="particle-p-t-rel-and-relative-jet-mass-distributions-of-real-jets-and-those-generated-by-mpgan-without-our-masking-strategy"></span>
<div class="centerline"> <img alt="PIC" src="figures/04-ML4Sim/mpgan/masking/zeropaddingfig-.png" style="max-width:100%"/> </div>
<figcaption class="caption"><span class="id"><span class="ec-lmbx-12">Figure C.2.                                                                     </span></span><span class="content">Particle
<!--  l. 93  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow><mi>p</mi></mrow><mrow><mstyle mathvariant="normal"><mi>T</mi></mstyle></mrow><mrow><mstyle mathvariant="normal"><mi>rel</mi></mstyle></mrow></msubsup></math>
and relative jet mass distributions of real jets and those generated by MPGAN
without our masking strategy. Left: gluon, right: light quark jets. We see that
while for gluon jets the generator learns distributions correctly, it struggles to
learn the discontinuous spike, due to the zero-padded particles, in the light quark
<!--  l. 93  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow><mi>p</mi></mrow><mrow><mstyle mathvariant="normal"><mi>T</mi></mstyle></mrow><mrow><mstyle mathvariant="normal"><mi>rel</mi></mstyle></mrow></msubsup></math>
distribution. This also leads to a distorted mass distribution.                    </span></figcaption><!--  tex4ht:label?: x91-360001r2   -->
</figure>
<!--  l. 97  --><p class="indent">       In the <span class="small-caps">JetNet</span> dataset used for training MPGAN, jets with fewer than 30
particles are zero-padded to fill the 30-particle point cloud. Such zero-padded particles
pose a problem for the generator, which is not able to learn this sharp discontinuity in
the jet constituents (Figure <a href="#particle-p-t-rel-and-relative-jet-mass-distributions-of-real-jets-and-those-generated-by-mpgan-without-our-masking-strategy">C.2<!--  tex4ht:ref: fig:04_mpgan_zeropadding   --></a>).
</p>
<figure class="figure" id="x91-360002r3"><span id="the-four-alternative-masking-strategies-which-we-test-"></span>
<div class="centerline"> <img alt="PIC" src="figures/04-ML4Sim/mpgan/masking/masking-.png" style="max-width:100%"/> </div>
<figcaption class="caption"><span class="id"><span class="ec-lmbx-12">Figure C.3. </span></span><span class="content">The four alternative masking strategies which we test.             </span></figcaption><!--  tex4ht:label?: x91-360002r3   -->
</figure>
<figure class="figure" id="x91-360003r4"><span id="loss-curve-of-a-training-on-light-quark-jets-with-masking-strategy-typical-of-loss-curves-with-all-four-strategies-"></span>
<div class="centerline"> <img alt="PIC" src="figures/04-ML4Sim/mpgan/masking/masking_loss-.png" style="max-width:60%"/> </div>
<figcaption class="caption"><span class="id"><span class="ec-lmbx-12">Figure C.4. </span></span><span class="content">Loss curve of a training on light quark jets with masking strategy
3, typical of loss curves with all four strategies.                                  </span></figcaption><!--  tex4ht:label?: x91-360003r4   -->
</figure>
<!--  l. 117  --><p class="indent">       To counter this issue, we experiment with five masking strategies, out of which
the one described in Section <a href="MessagepassingGANs.html#architecture">10.1.2<!--  tex4ht:ref: sec:04_mpgan_arch   --></a> was most successful. The four alternatives, which all
involve the generator learning the mask without any external input, are shown in
Figure <a href="#the-four-alternative-masking-strategies-which-we-test-">C.3<!--  tex4ht:ref: fig:04_mpgan_masking   --></a>.
</p><!--  l. 120  --><p class="indent">       Strategy 1 treats the mask homogeneously as an extra feature to learn.
A variation of this weights the nodes in the discriminator the mask. In
strategy 2, a mask is calculated for each generated particle as a function of its
<!--  l. 122  --><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mrow><mi>p</mi></mrow><mrow><mstyle mathvariant="normal"><mi>T</mi></mstyle></mrow><mrow><mstyle mathvariant="normal"><mi>rel</mi></mstyle></mrow></msubsup></math>,
based on an empirical minimum cutoff in the dataset. In particular, both a
Heaviside-step-function and a continuous mask function as in the figure are tested. The
standard MP discriminator, as described in Section <a href="MessagepassingGANs.html#architecture">10.1.2<!--  tex4ht:ref: sec:04_mpgan_arch   --></a>, is used. Strategy 3 sees the
generator applying an FC layer per particle in the initial cloud to learn their respective
masks, with both the MP discriminator, as well as a variant with the number of
unmasked nodes in the clouds added as an extra feature to the FC layer. In strategies 1
and 3 we test both binary and continuous masks. Finally, in strategy 4, we train
an auxiliary network to choose a number of particles to mask (as opposed to
sampling from the real distribution), which is then passed into the standard MP
generator.
</p><!--  l. 130  --><p class="indent">       We find that all such strategies are unable to produce accurate light quark jets,
and in fact trainings for each diverge in the fashion depicted in Figure <a href="#loss-curve-of-a-training-on-light-quark-jets-with-masking-strategy-typical-of-loss-curves-with-all-four-strategies-">C.4<!--  tex4ht:ref: fig:04_mpgan_masking_loss   --></a>, even using
each discriminator regularization method mentioned in Appendix <a href="#training-and-implementation-details">C.1.2<!--  tex4ht:ref: app:04_mpgan_training   --></a>). We conclude
                                                                                

                                                                                
that learning the number of particles to produce is a significant challenge for a
generator network, but is a relatively simple feature with which to discriminate
between real and fake jets. To equalize this we use the strategy in Section <a href="MessagepassingGANs.html#architecture">10.1.2<!--  tex4ht:ref: sec:04_mpgan_arch   --></a>
where the number of particles to produce is sampled directly from the real
distribution, removing the burden of learning this distribution from the generator
network.
                                                                                

                                                                                
                                                                                

                                                                                
</p>
<nav class="crosslinks-bottom"> <a href="SupplementaryMaterialforChapterrefsec04models.html">⭠</a> <a href="GenerativeAdversarialParticleTransformers.html">⭢</a> </nav> <div class="footer"><p>Copyright © 2024 Raghav Kansal. All rights reserved.</p></div></main>
</body>
</html>