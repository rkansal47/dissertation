<!DOCTYPE html>

<html lang="en-US" xml:lang="en-US">
<head><title>Introduction</title>
<meta charset="utf-8"/>
<meta content="TeX4ht (https://tug.org/tex4ht/)" name="generator"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<link href="main.css" rel="stylesheet" type="text/css"/>
<meta content="main.tex" name="src"/>
<script async="async" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/mml-chtml.js" type="text/javascript"></script>
<link href="style.css" rel="stylesheet" type="text/css"/>
<link href="assets/icon.png" rel="icon" type="image/x-icon"/>
</head><body>
<nav class="TOC"><span class="mainToc" id="mainToc"><a href="index.html"><img alt="Symmetries, QFT, &amp; The Standard Model" class="mainTocLogo" src="assets/logo.png" width="100%"/></a></span>
<span class="likepartToc"><a href="Frontmatter.html#front-matter">Front matter</a></span>
<span class="likepartToc"><a href="AbstractoftheDissertation.html#abstract-of-the-dissertation">Abstract of the Dissertation</a></span>
<span class="likepartToc"><a href="Introduction.html#introduction">Introduction</a></span>
<span class="partToc">I  <a href="TheoreticalBackground.html#theoretical-background">Theoretical Background</a></span>
<span class="partToc">II  <a href="ExperimentalBackground.html#experimental-background">Experimental Background</a></span>
<span class="partToc">III  <a href="AIMLandStatisticsBackground.html#aiml-and-statistics-background">AI/ML and Statistics Background</a></span>
<span class="partToc">IV  <a href="AcceleratingSimulationswithAI.html#accelerating-simulations-with-ai">Accelerating Simulations with AI</a></span>
<span class="partToc">V  <a href="SearchesforHighEnergyHiggsBosonPairs.html#searches-for-high-energy-higgs-boson-pairs">Searches for High Energy Higgs Boson Pairs</a></span>
<span class="partToc">VI  <a href="AIforJets.html#ai-for-jets">AI for Jets</a></span>
<span class="chapterToc">15 <a href="IntroductionandtheJetNetPackage.html#introduction-and-the-jetnet-package">Introduction and the JetNet Package</a></span>
<span class="chapterToc">16 <a href="Lorentzgroupequivariantautoencoders.html#lorentzgroup-equivariant-autoencoders">Lorentz-group equivariant autoencoders</a></span>
<span class="sectionToc">16.1 <a href="#introduction3">Introduction</a></span>
<span class="sectionToc">16.2 <a href="LGAEarchitecture.html#lgae-architecture">LGAE architecture</a></span>
<span class="sectionToc">16.3 <a href="Experiments.html#experiments1">Experiments</a></span>
<span class="sectionToc">16.4 <a href="Conclusion.html#conclusion">Conclusion</a></span>
<span class="partToc">VII  <a href="Appendix.html#appendix">Appendix</a></span>
<span class="likepartToc"><a href="Bibliography.html#bibliography">Bibliography</a></span>
</nav>
<main class="main-content"><a class="header-link smallscreenhide" href="#mainToc" rel="noopener noreferrer" style="top: 11px; left: 150px;" target="_self"><img alt="Table of Contents" class="header-icon" src="assets/sidebar.png" style="width: 32px; height: 32px;"/></a><a class="header-link" href="https://www.raghavkansal.com" rel="noopener noreferrer" style="top: 13px; right: 12px;" target="_blank"><img alt="My website" class="header-icon" src="assets/icon.png" style="width: 26px; height: 26px;"/></a><a class="header-link" href="https://github.com/rkansal47/dissertation/blob/gh-pages/dissertation.pdf?raw=true" rel="noopener noreferrer" style="top: 13px; right: 85px;" target="_blank"><img alt="Download PDF" class="header-icon" src="assets/download.png" style="width: 25px; height: 25px;"/></a><a class="header-link" href="https://github.com/rkansal47/dissertation" rel="noopener noreferrer" style="top: 10px; right: 44px;" target="_blank"><img alt="GitHub Repository" class="header-icon" src="https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png" style="width: 32px; height: 32px;"/></a>
<nav class="crosslinks-top"> <a href="Lorentzgroupequivariantautoencoders.html">⭠</a> <a href="LGAEarchitecture.html">⭢</a> </nav>
<h3 class="sectionHead" id="introduction3"><span class="titlemark">16.1   </span> <a id="x77-28400016.1"></a>Introduction</h3>
<!--  l. 78  --><p class="noindent">In this chapter, we present the first Lorentz-group-equivariant autoencoder (LGAE) for
jets. As described in Chapter <a href="Autoencodersandgenerativemodels.html#autoencoders-and-generative-models">7.3<!--  tex4ht:ref: sec:03_genaes   --></a>, autoencoders are networks that learn to encode
input data into, and decode data from, a low dimensional latent space, and
thus have interesting applications in data compression [<a href="Bibliography.html#XAE-data-compression-1">414</a>, <a href="Bibliography.html#XAE-data-compression-2">415</a>] and anomaly
detection [<a href="Bibliography.html#XTsan_2021brw">67</a>, <a href="Bibliography.html#XFarina-anomaly">248</a>, <a href="Bibliography.html#XFinke-anomaly">250</a>, <a href="Bibliography.html#XAtkinson_2021nlt">262</a>, <a href="Bibliography.html#XAE-anomaly">416</a>–<a href="Bibliography.html#XQUAK">419</a>]. Both tasks are particularly relevant for
HEP: the former to cope with the storage and processing of the ever-increasing
data collected at the LHC; and the latter for model-agnostic searches for new
physics.
</p><!--  l. 82  --><p class="indent">       Incorporating Lorentz equivariance into an autoencoder has the potential
to not only increase performance in both respects, but also provide a more
interpretable latent space and reduce training data requirements. As discussed in
Chapter <a href="Equivariantneuralnetworks.html#equivariant-neural-networks">7.2<!--  tex4ht:ref: sec:03_ml_equivariantnns   --></a>, Lorentz symmetry has been successfully exploited recently in HEP for jet
classification [<a href="Bibliography.html#Xbogatskiy2020lorentz">54</a>, <a href="Bibliography.html#XLorentzNet">420</a>–<a href="Bibliography.html#XButter_2018">422</a>], with competitive and even SOTA results. In the same
spirit, we aim to extend these developments to an autoencoder and explore its
performance and interpretability. To do so, we employ the Fourier space approach
discussed above, which uses the set of irreducible representations (irreps) of the
Lorentz-group as the basis for constructing equivariant maps. We also train alternative
architectures, including GNNs and convolutional neural networks (CNNs), with different
inherent symmetries and find the LGAE outperforms them on reconstruction and
anomaly detection tasks.
                                                                                

                                                                                
</p><!--  l. 88  --><p class="indent">       The principal results of this work demonstrate (1) that the advantage of
incorporating Lorentz equivariance extends beyond whole jet classification
to applications with particle-level outputs and (2) the interpretability of
Lorentz-equivariant models. The key challenges overcome in this work include: (1)
training an equivariant autoencoder via particle-to-particle and permutation-invariant
set-to-set losses (Section <a href="Experiments.html#experiments1">16.3<!--  tex4ht:ref: sec:06_lgae_experiments   --></a>); (2) defining a jet-level compression scheme
for the latent space (Section <a href="LGAEarchitecture.html#lgae-architecture">16.2<!--  tex4ht:ref: sec:06_lgae_architecture   --></a>); and (3) optimizing the architecture for
different tasks, such as reconstruction (Section <a href="Experiments.html#reconstruction">16.3.3<!--  tex4ht:ref: sec:06_lgae_reconstruction   --></a>) and anomaly detection
(Section <a href="Experiments.html#anomaly-detection">16.3.4<!--  tex4ht:ref: sec:06_lgae_anomaly   --></a>).
</p><!--  l. 91  --><p class="indent">       This paper is structured as follows. We present the LGAE architecture in
Section <a href="LGAEarchitecture.html#lgae-architecture">16.2<!--  tex4ht:ref: sec:06_lgae_architecture   --></a>, and discuss experimental results on the reconstruction and anomaly
detection of high energy jets in Section <a href="Experiments.html#experiments1">16.3<!--  tex4ht:ref: sec:06_lgae_experiments   --></a>. We also demonstrate the interpretability of
the model, by analyzing its latent space, and its data efficiency relative to baseline
models. Finally, we conclude in Section <a href="Conclusion.html#conclusion">16.4<!--  tex4ht:ref: sec:06_lgae_conclusion   --></a>.
                                                                                

                                                                                
</p>
<nav class="crosslinks-bottom"> <a href="Lorentzgroupequivariantautoencoders.html">⭠</a> <a href="LGAEarchitecture.html">⭢</a> </nav> <div class="footer"><p>Copyright © 2024 Raghav Kansal. All rights reserved.</p></div></main>
</body>
</html>